{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93a93ebf",
   "metadata": {},
   "source": [
    "# Test set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ca10f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classes for preprocessing\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "import numpy as np\n",
    "\n",
    "# select specific columns for pipeline\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values\n",
    "\n",
    "# preprocessing:\n",
    "# - merge in store data\n",
    "# - add additional columns\n",
    "# - remove unneeded rows and columns\n",
    "class AttributeAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.storefile = pd.read_csv('data/store.csv')\n",
    "    def fit(self, X, y=None):\n",
    "        X['Date'] = pd.to_datetime(X['Date'], errors='coerce')\n",
    "        last_date = max(X['Date'])\n",
    "        interval_start = last_date - DateOffset(months=3)\n",
    "        self.stores = X.loc[(X['Store'] > 0) & (X['Sales'] > 0) & (X['Date'] > interval_start), \n",
    "                            ['Store', 'Sales']].groupby(['Store'])\n",
    "        \n",
    "        return self\n",
    "    def transform(self, X, y=None):     \n",
    "        \n",
    "        # remove Sales =0 \n",
    "        X = X[X['Sales'] > 0]\n",
    "        \n",
    "        # remove Stores without id\n",
    "        X = X[X['Store'] > 0]\n",
    "    \n",
    "        \n",
    "        # merge in store data\n",
    "        X = pd.merge(X, self.storefile, how='left', on='Store')\n",
    "        \n",
    "        # create features mean and median of Sales per store over last 3 months\n",
    " \n",
    "        for store, v in self.stores['Sales']:\n",
    "            X.loc[X['Store'] == store, 'Store_mean'] = v.mean()\n",
    "            X.loc[X['Store'] == store, 'Store_median'] = v.median()\n",
    "       \n",
    "        # Create more date columns\n",
    "        X['Date'] = pd.to_datetime(X['Date'], errors='coerce')\n",
    "        X['Year'] = X.Date.dt.year\n",
    "        X['Month'] = X.Date.dt.month\n",
    "        X['DayOfWeek'] = X.Date.dt.dayofweek\n",
    "        \n",
    "        # Create feature Competition since months, cap for high values\n",
    "        X[\"CompetitionSinceMonths\"] = ((X['Year']- X['CompetitionOpenSinceYear']) * 12 +\n",
    "                                           (X['Month'] - X['CompetitionOpenSinceMonth']))\n",
    "        X.loc[X[\"CompetitionSinceMonths\"] < 0, \"CompetitionSinceMonths\"] = 0\n",
    "        X.loc[X[\"CompetitionSinceMonths\"] > 24, \"CompetitionSinceMonths\"] = 24\n",
    "        \n",
    "        # Set competition distance at cap if competition is not yet open\n",
    "        max_distance = 10000.\n",
    "        X.loc[X[\"CompetitionSinceMonths\"] == 0, 'CompetitionDistance'] = max_distance\n",
    "        X.loc[X['CompetitionDistance'] > max_distance, 'CompetitionDistance']  = max_distance\n",
    "        \n",
    "        # Create promo since column, cap for high values\n",
    "        X[\"Promo2SinceWeeks\"] = ((X['Year']- X['Promo2SinceYear']) * 52 +\n",
    "                                           (X['Month'] - X['Promo2SinceWeek']))\n",
    "        X.loc[X[\"Promo2SinceWeeks\"] < 0, \"Promo2SinceWeeks\"] = 0\n",
    "        X.loc[X[\"Promo2SinceWeeks\"] > 12, \"Promo2SinceWeeks\"] = 12\n",
    "        \n",
    "        # Clean up state holiday\n",
    "        X['StateHoliday'] = X['StateHoliday'].replace(0.0, \"0\")\n",
    "        X['StateHoliday'] = X['StateHoliday'].replace(\"0\", 0)\n",
    "        X['StateHoliday'] = X['StateHoliday'].replace(\"a\", \"Public\")\n",
    "        X['StateHoliday'] = X['StateHoliday'].replace(\"b\", \"Easter\")\n",
    "        X['StateHoliday'] = X['StateHoliday'].replace(\"c\", \"Christmas\")\n",
    "        \n",
    "        # drop columns\n",
    "        X = X.drop(columns = ['Customers', 'Open', \"CompetitionOpenSinceMonth\",\n",
    "                             'CompetitionOpenSinceYear', 'Promo2SinceWeek', 'Promo2SinceYear',\n",
    "                             'PromoInterval', 'Date']\n",
    "        )\n",
    "        self.attribute_names = X.columns\n",
    "        return X\n",
    "\n",
    "\n",
    "# define evaluation metrics RMSPE\n",
    "def metric(preds, actuals):\n",
    "    preds = preds.reshape(-1)\n",
    "    actuals = actuals.reshape(-1)\n",
    "    assert preds.shape == actuals.shape\n",
    "    return 100 * np.linalg.norm((actuals - preds) / actuals) / np.sqrt(preds.shape[0])\n",
    "\n",
    "\n",
    "# full pipeline including attribute adding, missing value imputing\n",
    "# one-hot encoding\n",
    "def full_pipeline(data, fit=True):\n",
    "    \n",
    "    if fit:\n",
    "        transformed = pp.fit_transform(data)\n",
    "    else:\n",
    "        transformed = pp.transform(data) \n",
    "    \n",
    "    impute_miss_cat = ['SchoolHoliday', 'StateHoliday', \"Promo\"]\n",
    "    si = SimpleImputer(strategy=\"constant\", fill_value = 0)\n",
    "    \n",
    "    dfs = DataFrameSelector(impute_miss_cat)\n",
    "    t = dfs.fit_transform(transformed)\n",
    "    cat_tr = si.fit_transform(t)\n",
    "\n",
    "    transformed.loc[:, impute_miss_cat] = cat_tr\n",
    "    \n",
    "    numerical_features = ['CompetitionDistance', \"CompetitionSinceMonths\", \"Promo2SinceWeeks\"]\n",
    "                    \n",
    "    target = ['Sales']\n",
    "    num_columns = numerical_features + target\n",
    "    num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_columns)),\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "       \n",
    "    ])\n",
    "    \n",
    "    num_tr = num_pipeline.fit_transform(transformed)\n",
    "    transformed.loc[:, num_columns] = num_tr        \n",
    "    \n",
    "    one_hot_cat = ['StateHoliday', 'StoreType', 'Assortment',\n",
    "                   'Month', 'DayOfWeek']\n",
    "    transformed = pd.get_dummies(transformed, columns=one_hot_cat)\n",
    "    return transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7faa7bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sabine/miniconda3/envs/minicomp/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (7) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "import pandas as pd\n",
    "train_data = pd.read_csv(\"data/train.csv\")\n",
    "store = pd.read_csv('data/store.csv')\n",
    "\n",
    "\n",
    "# Insert test data link here\n",
    "test = pd.read_csv(\"https://raw.githubusercontent.com/igivis7/dsr28_minicomp_team1/main/data/holdout.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86ee0f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run preprocessing on training to fit some values\n",
    "pp = AttributeAdder()\n",
    "train_transformed = full_pipeline(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da03007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run preprocessing on test set\n",
    "test_trans = full_pipeline(test, fit=False)\n",
    "for c in train_transformed.columns:\n",
    "    if not c in test_trans.columns:\n",
    "        test_trans[c] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bb4bddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns to keep\n",
    "keep_columns = [\"Promo\", \"Promo2SinceWeeks\", \"CompetitionSinceMonths\", \n",
    "                \"Store_mean\", \"CompetitionDistance\", \"Month_12\", \"DayOfWeek_0\", \n",
    "                \"DayOfWeek_1\", \"DayOfWeek_5\"]\n",
    "\n",
    "X_train = train_transformed.loc[:, keep_columns]\n",
    "y_train = train_transformed['Sales']\n",
    "X_valid = test_trans.loc[:, keep_columns]\n",
    "y_valid = test_trans['Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b82478a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: decision tree, RMSPE=26.51%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import pickle\n",
    "\n",
    "tree_reg_trained = pickle.load(open(\"model/tree_26.5.sav\", \"rb\"))\n",
    "y_pred = tree_reg_trained.predict(X_valid)\n",
    "rmspe = metric(y_pred, np.array(y_valid))\n",
    "print(f'Prediction: decision tree, RMSPE={rmspe:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "minicomp",
   "language": "python",
   "name": "minicomp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
